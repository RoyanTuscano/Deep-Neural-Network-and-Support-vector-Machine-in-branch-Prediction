{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('./ML_Data/CLIENT01_ML.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples=2000000\n",
    "X = data[:samples,1:-18]\n",
    "Y = data[:samples,-2:-1]\n",
    "PC_Address=data[:samples,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000,) (2000000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(PC_Address.shape,Y.shape)\n",
    "#x=int(PC_Address[1000]%10000)\n",
    "#print(x)\n",
    "#print(PC_Address[x])\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 126) (10, 1) (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/roy/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "batch_size=1\n",
    "#Global Histroy with size of register 100\n",
    "GHR=np.zeros((10,100))\n",
    "#Local History with 1000 enteries of Local History parsed with the address. Each register size if 10\n",
    "LHR=np.zeros((1000,10))\n",
    "clf = Perceptron(penalty='l2')\n",
    "X_input=np.concatenate((X[0:10],GHR[0:10],LHR[0:10]),axis=1)\n",
    "clf.fit(X_input,Y[0:10])\n",
    "print(X_input.shape,Y[0:10].shape,GHR[0,:].shape)\n",
    "acc=0\n",
    "add=int(PC_Address[0]%1000)\n",
    "result=np.zeros((1,samples))\n",
    "for i in range(0,samples,batch_size):\n",
    "    add=int(PC_Address[i]%1000)\n",
    "    # the input vector to the Neural network that has GHR, LHR and PC\n",
    "    x_input=np.concatenate((X[i:i+1],GHR[0:1],LHR[add:add+1]),axis=1)\n",
    "    y_output=Y[i:i+1]\n",
    "    y_pred=clf.predict(x_input)\n",
    "    clf.partial_fit(x_input,y_output)\n",
    "    GHR[0,:-1]=GHR[0,1:]\n",
    "    GHR[0,-1]=Y[i:i+1,0]\n",
    "    LHR[add,:-1]=LHR[add,1:]\n",
    "    LHR[add,-1]=Y[i:i+1,0]\n",
    "    if(y_pred==Y[i:i+1,0]):\n",
    "        acc=acc+1\n",
    "    result[0,i]=acc\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n",
      "0 cycle accuracy 0.0\n",
      "1 cycle accuracy 0.8842\n",
      "2 cycle accuracy 0.9314\n",
      "3 cycle accuracy 0.9173\n",
      "4 cycle accuracy 0.9271\n",
      "5 cycle accuracy 0.9162\n",
      "6 cycle accuracy 0.9407\n",
      "7 cycle accuracy 0.934\n",
      "8 cycle accuracy 0.9074\n",
      "9 cycle accuracy 0.9447\n",
      "10 cycle accuracy 0.955\n",
      "11 cycle accuracy 0.9144\n",
      "12 cycle accuracy 0.8374\n",
      "13 cycle accuracy 0.9279\n",
      "14 cycle accuracy 0.9988\n",
      "15 cycle accuracy 0.9487\n",
      "16 cycle accuracy 0.9835\n",
      "17 cycle accuracy 0.9691\n",
      "18 cycle accuracy 0.9204\n",
      "19 cycle accuracy 0.9235\n",
      "20 cycle accuracy 0.9248\n",
      "21 cycle accuracy 0.8465\n",
      "22 cycle accuracy 0.9137\n",
      "23 cycle accuracy 0.9353\n",
      "24 cycle accuracy 0.9446\n",
      "25 cycle accuracy 0.8767\n",
      "26 cycle accuracy 0.8977\n",
      "27 cycle accuracy 0.9468\n",
      "28 cycle accuracy 0.9224\n",
      "29 cycle accuracy 0.8473\n",
      "30 cycle accuracy 0.9103\n",
      "31 cycle accuracy 0.8581\n",
      "32 cycle accuracy 0.9128\n",
      "33 cycle accuracy 0.909\n",
      "34 cycle accuracy 0.9236\n",
      "35 cycle accuracy 0.9134\n",
      "36 cycle accuracy 0.908\n",
      "37 cycle accuracy 0.9201\n",
      "38 cycle accuracy 0.8574\n",
      "39 cycle accuracy 0.9107\n",
      "40 cycle accuracy 0.9134\n",
      "41 cycle accuracy 0.9259\n",
      "42 cycle accuracy 0.8709\n",
      "43 cycle accuracy 0.9087\n",
      "44 cycle accuracy 0.9016\n",
      "45 cycle accuracy 0.8637\n",
      "46 cycle accuracy 0.9131\n",
      "47 cycle accuracy 0.9327\n",
      "48 cycle accuracy 0.8546\n",
      "49 cycle accuracy 0.9039\n",
      "50 cycle accuracy 0.9126\n",
      "51 cycle accuracy 0.863\n",
      "52 cycle accuracy 0.9119\n",
      "53 cycle accuracy 0.9366\n",
      "54 cycle accuracy 0.8804\n",
      "55 cycle accuracy 0.8759\n",
      "56 cycle accuracy 0.9453\n",
      "57 cycle accuracy 0.9111\n",
      "58 cycle accuracy 0.9154\n",
      "59 cycle accuracy 0.8445\n",
      "60 cycle accuracy 0.9238\n",
      "61 cycle accuracy 0.8704\n",
      "62 cycle accuracy 0.906\n",
      "63 cycle accuracy 0.921\n",
      "64 cycle accuracy 0.9401\n",
      "65 cycle accuracy 0.9352\n",
      "66 cycle accuracy 0.9355\n",
      "67 cycle accuracy 0.8554\n",
      "68 cycle accuracy 0.9221\n",
      "69 cycle accuracy 0.9315\n",
      "70 cycle accuracy 0.8621\n",
      "71 cycle accuracy 0.9342\n",
      "72 cycle accuracy 0.9318\n",
      "73 cycle accuracy 0.8614\n",
      "74 cycle accuracy 0.9192\n",
      "75 cycle accuracy 0.9303\n",
      "76 cycle accuracy 0.9323\n",
      "77 cycle accuracy 0.9224\n",
      "78 cycle accuracy 0.9192\n",
      "79 cycle accuracy 0.8548\n",
      "80 cycle accuracy 0.9063\n",
      "81 cycle accuracy 0.8911\n",
      "82 cycle accuracy 0.8893\n",
      "83 cycle accuracy 0.9017\n",
      "84 cycle accuracy 0.8639\n",
      "85 cycle accuracy 0.9278\n",
      "86 cycle accuracy 0.9153\n",
      "87 cycle accuracy 0.8534\n",
      "88 cycle accuracy 0.9077\n",
      "89 cycle accuracy 0.8925\n",
      "90 cycle accuracy 0.8867\n",
      "91 cycle accuracy 0.9253\n",
      "92 cycle accuracy 0.885\n",
      "93 cycle accuracy 0.8935\n",
      "94 cycle accuracy 0.9218\n",
      "95 cycle accuracy 0.8649\n",
      "96 cycle accuracy 0.9134\n",
      "97 cycle accuracy 0.8732\n",
      "98 cycle accuracy 0.9117\n",
      "99 cycle accuracy 0.8998\n",
      "100 cycle accuracy 0.882\n",
      "101 cycle accuracy 0.9232\n",
      "102 cycle accuracy 0.867\n",
      "103 cycle accuracy 0.9146\n",
      "104 cycle accuracy 0.8948\n",
      "105 cycle accuracy 0.8591\n",
      "106 cycle accuracy 0.9068\n",
      "107 cycle accuracy 0.8558\n",
      "108 cycle accuracy 0.907\n",
      "109 cycle accuracy 0.8788\n",
      "110 cycle accuracy 0.9004\n",
      "111 cycle accuracy 0.9335\n",
      "112 cycle accuracy 0.8663\n",
      "113 cycle accuracy 0.9066\n",
      "114 cycle accuracy 0.9258\n",
      "115 cycle accuracy 0.8639\n",
      "116 cycle accuracy 0.9169\n",
      "117 cycle accuracy 0.8674\n",
      "118 cycle accuracy 0.9236\n",
      "119 cycle accuracy 0.9057\n",
      "120 cycle accuracy 0.8859\n",
      "121 cycle accuracy 0.9063\n",
      "122 cycle accuracy 0.8571\n",
      "123 cycle accuracy 0.9069\n",
      "124 cycle accuracy 0.8675\n",
      "125 cycle accuracy 0.9025\n",
      "126 cycle accuracy 0.9168\n",
      "127 cycle accuracy 0.8626\n",
      "128 cycle accuracy 0.9125\n",
      "129 cycle accuracy 0.9338\n",
      "130 cycle accuracy 0.8569\n",
      "131 cycle accuracy 0.9185\n",
      "132 cycle accuracy 0.8634\n",
      "133 cycle accuracy 0.9013\n",
      "134 cycle accuracy 0.9216\n",
      "135 cycle accuracy 0.8682\n",
      "136 cycle accuracy 0.9092\n",
      "137 cycle accuracy 0.8661\n",
      "138 cycle accuracy 0.9183\n",
      "139 cycle accuracy 0.8836\n",
      "140 cycle accuracy 0.8755\n",
      "141 cycle accuracy 0.9098\n",
      "142 cycle accuracy 0.8429\n",
      "143 cycle accuracy 0.9139\n",
      "144 cycle accuracy 0.8602\n",
      "145 cycle accuracy 0.9029\n",
      "146 cycle accuracy 0.9322\n",
      "147 cycle accuracy 0.8643\n",
      "148 cycle accuracy 0.9131\n",
      "149 cycle accuracy 0.9195\n",
      "150 cycle accuracy 0.8695\n",
      "151 cycle accuracy 0.9106\n",
      "152 cycle accuracy 0.862\n",
      "153 cycle accuracy 0.9256\n",
      "154 cycle accuracy 0.8894\n",
      "155 cycle accuracy 0.8927\n",
      "156 cycle accuracy 0.9101\n",
      "157 cycle accuracy 0.8595\n",
      "158 cycle accuracy 0.8953\n",
      "159 cycle accuracy 0.8401\n",
      "160 cycle accuracy 0.8847\n",
      "161 cycle accuracy 0.9163\n",
      "162 cycle accuracy 0.8559\n",
      "163 cycle accuracy 0.9099\n",
      "164 cycle accuracy 0.9329\n",
      "165 cycle accuracy 0.8542\n",
      "166 cycle accuracy 0.9196\n",
      "167 cycle accuracy 0.866\n",
      "168 cycle accuracy 0.909\n",
      "169 cycle accuracy 0.8937\n",
      "170 cycle accuracy 0.892\n",
      "171 cycle accuracy 0.907\n",
      "172 cycle accuracy 0.8561\n",
      "173 cycle accuracy 0.9004\n",
      "174 cycle accuracy 0.849\n",
      "175 cycle accuracy 0.9073\n",
      "176 cycle accuracy 0.9217\n",
      "177 cycle accuracy 0.8607\n",
      "178 cycle accuracy 0.9145\n",
      "179 cycle accuracy 0.9147\n",
      "180 cycle accuracy 0.877\n",
      "181 cycle accuracy 0.9213\n",
      "182 cycle accuracy 0.8601\n",
      "183 cycle accuracy 0.925\n",
      "184 cycle accuracy 0.8794\n",
      "185 cycle accuracy 0.8961\n",
      "186 cycle accuracy 0.9128\n",
      "187 cycle accuracy 0.8611\n",
      "188 cycle accuracy 0.8918\n",
      "189 cycle accuracy 0.8536\n",
      "190 cycle accuracy 0.9144\n",
      "191 cycle accuracy 0.9044\n",
      "192 cycle accuracy 0.8745\n",
      "193 cycle accuracy 0.9219\n",
      "194 cycle accuracy 0.901\n",
      "195 cycle accuracy 0.89\n",
      "196 cycle accuracy 0.9251\n",
      "197 cycle accuracy 0.8626\n",
      "198 cycle accuracy 0.9095\n",
      "199 cycle accuracy 0.8759\n"
     ]
    }
   ],
   "source": [
    "temp=0\n",
    "print(len(result[0]))\n",
    "for i in range(int(len(result[0])/10000)):\n",
    "    print(i,\"cycle accuracy\",(result[0,i*10000]-temp)/10000)\n",
    "    temp=result[0,i*10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
